# Proyecto MLOps

## Integrantes del Equipo
- Esteban Ramirez (Data Scientist)
- Allan Montes (MLOps Engineer)
- Anyelin Arias (Software Engineer)

## âœ… Checklist del Proyecto

- [x] El cÃ³digo de un modelo de AI para resolver un problema de machine learning o deep learning en un notebook de Python `.ipynb` o bien, la herramienta o lenguaje de su preferencia de su preferencia.
- [x] El script, software o cÃ³digo en general para automatizar el reentrenamiento del modelo.
- [x] El versionamiento del cÃ³digo que contenga el cÃ³digo realizado para el modelo de AI y el Script de reentrenamiento. Tomar en cuenta que en este versionamiento debe trabajar todo el equipo haciendo los pull requests necesarios en el branch de `develop`. TambiÃ©n debe contener al menos el branch de `develop`, `staging` y `main` (o `master` como deseen trabajarlo).
- [x] RealizaciÃ³n de un API para consumir el modelo de inteligencia artificial o bien, una interface grÃ¡fica web con Streamlit, ReactJS o el framework para GUIs web de su preferencia.
- [x] Realizar el sistema de conteinerizaciÃ³n con Docker o de su preferencia, listo para el deployment.
- [x] Realizar la seguridad en la validaciÃ³n de entradas del API y anÃ¡lisis estÃ¡tico del cÃ³digo usando DeepSource o su herramienta de preferencia
- [x] Debe realizar el CI/CD en Github Actions o su herramienta de preferencia (Jenkins, CircleCI, Gitlab, etc...) para el reentrenamiento del modelo y tambiÃ©n para enviarlo al ambiente de desarrollo en un servidor en la nube de su preferencia (puede ser AWS EC2 o cualquier otro).
- [x] Poner las instrucciones de ejecuciÃ³n y documentaciÃ³n del modelo de AI y el API (en caso de interface grÃ¡fica tambiÃ©n se necesitan saber cuÃ¡les son los inputs y los outputs del modelo) en un `README.md` dentro del repositorio central.
- [x] Realizar el versionamiento del modelo y de los datos usando DVC o su herramienta de preferencia y los datos junto con el modelo deben estar subidos a un object storage de la nube de su preferencia (puede ser AWS S3).

## DescripciÃ³n del problema
Utilizando caracterÃ­sticas particulares de corres electrÃ³nicos de phising y de los que no son phising,
se analizan con el fin de poder detectar posibles correos maliciosos.

## Dataset
Los datos utilizados para entrenar el modelo provienen de Kaggle:
[Email Phishing Dataset](https://www.kaggle.com/datasets/ethancratchley/email-phishing-dataset?resource=download)

### Inputs
El dataset contiene caracterÃ­sticas extraÃ­das de emails, como:

- `num_words:` NÃºmero de palabras en el email
- `num_unique_words:` NÃºmero de palabras Ãºnicas
- `num_stopwords:` Cantidad de palabras comunes (stopwords)
- `num_links:` NÃºmero de enlaces
- `num_unique_domains:` Cantidad de dominios Ãºnicos
- `num_email_addresses:` NÃºmero de direcciones de email
- `num_spelling_errors:` Cantidad de errores ortogrÃ¡ficos
- `num_urgent_keywords:` NÃºmero de palabras que indican urgencia

### Output

- `label:` Etiqueta binaria (0: legÃ­timo, 1: phishing)

## Modelo de Machine Learning

Para este proyecto se utilizÃ³ un **Random Forest Classifier**, optimizado mediante Grid Search para encontrar los mejores hiperparÃ¡metros.

## Estructura del Repositorio

```
ğŸ“ proyecto_mlops/                # Carpeta raÃ­z del proyecto
â”‚
â”œâ”€â”€ ğŸ“ .github/workflows/         # Automatizaciones CI/CD
â”‚   â””â”€â”€ ğŸ“„ main.yml               # Pipeline de GitHub Actions
â”‚
â”œâ”€â”€ ğŸ“ data/                      # Dataset versionado con DVC
â”‚   â””â”€â”€ ğŸ“„ mini_email_phishing_data.csv.dvc
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                 # Notebooks y artefactos de entrenamiento
â”‚   â”œâ”€â”€ ğŸ““ classification_model.ipynb      # Desarrollo del modelo
â”‚   â”œâ”€â”€ ğŸ“¦ classification_model.joblib     # Modelo serializado
â”‚   â”œâ”€â”€ ğŸ“Š confusion_matrix.png            # MÃ©tricas visuales
â”‚   â”œâ”€â”€ ğŸ“Š feature_importance.png
â”‚   â””â”€â”€ ğŸ“Š roc_curve.png
â”‚
â”œâ”€â”€ ğŸ“„ Dockerfile                 # Imagen de producciÃ³n para la API
â”œâ”€â”€ ğŸ“„ download_data.py           # Descarga del dataset desde S3
â”œâ”€â”€ ğŸ“„ endpoints.py               # FastAPI con endpoint de inferencia
â”œâ”€â”€ ğŸ“„ retraining.py              # Script de re-entrenamiento y mÃ©tricas
â”œâ”€â”€ ğŸ“„ requirements.txt           # Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ .gitignore                 # Archivos/dirs a excluir del control de versiones
â””â”€â”€ ğŸ“„ README.md                  # DocumentaciÃ³n del proyecto
```

## Requerimientos

Necesita instalar las siguientes herramientas:
- Python 3.12.10 o superior
- pip
- Virtualenv (opcional)

Comando para instalar las dependencias del proyecto:
```bash
pip install -r requirements.txt

